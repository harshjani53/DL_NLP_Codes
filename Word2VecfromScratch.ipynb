{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yi4byzXtUpv"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbr_inds= []+list(range(1,4))"
      ],
      "metadata": {
        "id": "WTGtp8vMXigz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PFquMQptZG5"
      },
      "source": [
        "def tokenize(text):\n",
        "    # obtains tokens with a least 1 alphabet\n",
        "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
        "    return pattern.findall(text.lower())\n",
        "\n",
        "def mapping(tokens):\n",
        "    word_to_id = dict()\n",
        "    id_to_word = dict()\n",
        "\n",
        "    for i, token in enumerate(set(tokens)):\n",
        "        word_to_id[token] = i\n",
        "        id_to_word[i] = token\n",
        "\n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "def generate_training_data(tokens, word_to_id, window_size):\n",
        "    N = len(tokens)\n",
        "    X, Y = [], []\n",
        "\n",
        "    for i in range(N):\n",
        "        nbr_inds = list(range(max(0, i - window_size), i)) + \\\n",
        "                   list(range(i + 1, min(N, i + window_size + 1)))\n",
        "        #print(nbr_inds)\n",
        "        #print(tokens[i])\n",
        "        for j in nbr_inds:\n",
        "            X.append(word_to_id[tokens[i]])\n",
        "            #print('X:',word_to_id[tokens[i]])\n",
        "            #print(tokens[j])\n",
        "            Y.append(word_to_id[tokens[j]])\n",
        "            #print('Y:',word_to_id[tokens[j]])\n",
        "\n",
        "    X = np.array(X)\n",
        "    X = np.expand_dims(X, axis=0)\n",
        "    Y = np.array(Y)\n",
        "    Y = np.expand_dims(Y, axis=0)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKMcaDgzt6o7",
        "outputId": "892fcd00-9c1f-4395-91f7-1c69dd70bfa0"
      },
      "source": [
        "doc = \"After the deduction of the costs of investing, \" \\\n",
        "      \"beating the stock market is a loser's game.\"\n",
        "tokens = tokenize(doc)\n",
        "print(tokens)\n",
        "word_to_id, id_to_word = mapping(tokens)\n",
        "print(word_to_id)\n",
        "print(id_to_word)\n",
        "X, Y = generate_training_data(tokens, word_to_id, 3)\n",
        "print(X)\n",
        "print(Y)\n",
        "vocab_size = len(id_to_word)\n",
        "print(vocab_size)\n",
        "m = Y.shape[1]\n",
        "print(m)\n",
        "# turn Y into one hot encoding\n",
        "Y_one_hot = np.zeros((vocab_size, m))\n",
        "Y_one_hot[Y.flatten(), np.arange(m)] = 1\n",
        "print(Y_one_hot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['after', 'the', 'deduction', 'of', 'the', 'costs', 'of', 'investing', 'beating', 'the', 'stock', 'market', 'is', 'a', \"loser's\", 'game']\n",
            "{'stock': 0, 'investing': 1, 'the': 2, 'is': 3, 'beating': 4, 'a': 5, 'of': 6, \"loser's\": 7, 'market': 8, 'deduction': 9, 'costs': 10, 'game': 11, 'after': 12}\n",
            "{0: 'stock', 1: 'investing', 2: 'the', 3: 'is', 4: 'beating', 5: 'a', 6: 'of', 7: \"loser's\", 8: 'market', 9: 'deduction', 10: 'costs', 11: 'game', 12: 'after'}\n",
            "[[12 12 12  2  2  2  2  9  9  9  9  9  6  6  6  6  6  6  2  2  2  2  2  2\n",
            "  10 10 10 10 10 10  6  6  6  6  6  6  1  1  1  1  1  1  4  4  4  4  4  4\n",
            "   2  2  2  2  2  2  0  0  0  0  0  0  8  8  8  8  8  8  3  3  3  3  3  3\n",
            "   5  5  5  5  5  7  7  7  7 11 11 11]]\n",
            "[[ 2  9  6 12  9  6  2 12  2  6  2 10 12  2  9  2 10  6  2  9  6 10  6  1\n",
            "   9  6  2  6  1  4  6  2 10  1  4  2  2 10  6  4  2  0 10  6  1  2  0  8\n",
            "   6  1  4  0  8  3  1  4  2  8  3  5  4  2  0  3  5  7  2  0  8  5  7 11\n",
            "   0  8  3  7 11  8  3  5 11  3  5  7]]\n",
            "13\n",
            "84\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSuWqWbzWEXq",
        "outputId": "4f505dc8-4e7d-431d-945a-7e47d913aef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  8,  2,  5,  8,  2,  0,  5,  0,  2,  0,  3,  5,  0,  8,  0,  3,\n",
              "        2,  0,  8,  2,  3,  2, 11,  8,  2,  0,  2, 11,  7,  2,  0,  3, 11,\n",
              "        7,  0,  0,  3,  2,  7,  0,  4,  3,  2, 11,  0,  4,  9,  2, 11,  7,\n",
              "        4,  9, 12, 11,  7,  0,  9, 12,  6,  7,  0,  4, 12,  6, 10,  0,  4,\n",
              "        9,  6, 10,  1,  4,  9, 12, 10,  1,  9, 12,  6,  1, 12,  6, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(84)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxEEV4JGWX1Y",
        "outputId": "9e866206-d301-4081-f2cd-1f57357dee1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPaZTo8nuAcD",
        "outputId": "bb286313-dbe8-4d5e-ff73-ec6c54852c42"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 84)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raid0GnKwteX"
      },
      "source": [
        "def initialize_wrd_emb(vocab_size, emb_size):\n",
        "    \"\"\"\n",
        "    vocab_size: int. vocabulary size of your corpus or training data\n",
        "    emb_size: int. word embedding size. How many dimensions to represent each vocabulary\n",
        "    \"\"\"\n",
        "    WRD_EMB = np.random.randn(vocab_size, emb_size) * 0.01\n",
        "\n",
        "    # assert(WRD_EMB.shape == (vocab_size, emb_size))\n",
        "    return WRD_EMB\n",
        "\n",
        "def initialize_dense(input_size, output_size):\n",
        "    \"\"\"\n",
        "    input_size: int. size of the input to the dense layer\n",
        "    output_szie: int. size of the output out of the dense layer\n",
        "    \"\"\"\n",
        "    W = np.random.randn(output_size, input_size) * 0.01\n",
        "\n",
        "    #assert(W.shape == (output_size, input_size))\n",
        "    return W\n",
        "\n",
        "def initialize_parameters(vocab_size, emb_size):\n",
        "    WRD_EMB = initialize_wrd_emb(vocab_size, emb_size)\n",
        "    W = initialize_dense(emb_size, vocab_size)\n",
        "\n",
        "    parameters = {}\n",
        "    parameters['WRD_EMB'] = WRD_EMB\n",
        "    parameters['W'] = W\n",
        "\n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufAFalZoze4H"
      },
      "source": [
        "def ind_to_word_vecs(inds, parameters):\n",
        "    \"\"\"\n",
        "    inds: numpy array. shape: (1, m)\n",
        "    parameters: dict. weights to be trained\n",
        "    \"\"\"\n",
        "    m = inds.shape[1]\n",
        "    WRD_EMB = parameters['WRD_EMB']\n",
        "    word_vec = WRD_EMB[inds.flatten(), :].T\n",
        "\n",
        "    assert(word_vec.shape == (WRD_EMB.shape[1], m))\n",
        "\n",
        "    return word_vec\n",
        "\n",
        "def linear_dense(word_vec, parameters):\n",
        "    \"\"\"\n",
        "    word_vec: numpy array. shape: (emb_size, m)\n",
        "    parameters: dict. weights to be trained\n",
        "    \"\"\"\n",
        "    m = word_vec.shape[1]\n",
        "    W = parameters['W']\n",
        "    Z = np.dot(W, word_vec)\n",
        "\n",
        "    assert(Z.shape == (W.shape[0], m))\n",
        "\n",
        "    return W, Z\n",
        "\n",
        "def softmax(Z):\n",
        "    \"\"\"\n",
        "    Z: output out of the dense layer. shape: (vocab_size, m)\n",
        "    \"\"\"\n",
        "    softmax_out = np.divide(np.exp(Z), np.sum(np.exp(Z), axis=0, keepdims=True) + 0.001)\n",
        "\n",
        "    assert(softmax_out.shape == Z.shape)\n",
        "    return softmax_out\n",
        "\n",
        "def forward_propagation(inds, parameters):\n",
        "    word_vec = ind_to_word_vecs(inds, parameters)\n",
        "    W, Z = linear_dense(word_vec, parameters)\n",
        "    softmax_out = softmax(Z)\n",
        "\n",
        "    caches = {}\n",
        "    caches['inds'] = inds\n",
        "    caches['word_vec'] = word_vec\n",
        "    caches['W'] = W\n",
        "    caches['Z'] = Z\n",
        "\n",
        "    return softmax_out, caches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuGsS8hPzjUx"
      },
      "source": [
        "def cross_entropy(softmax_out, Y):\n",
        "    \"\"\"\n",
        "    softmax_out: output out of softmax. shape: (vocab_size, m)\n",
        "    \"\"\"\n",
        "    m = softmax_out.shape[1]\n",
        "    cost = -(1 / m) * np.sum(np.sum(Y * np.log(softmax_out + 0.001), axis=0, keepdims=True), axis=1)\n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNHj1ajzzp7A"
      },
      "source": [
        "def softmax_backward(Y, softmax_out):\n",
        "    \"\"\"\n",
        "    Y: labels of training data. shape: (vocab_size, m)\n",
        "    softmax_out: output out of softmax. shape: (vocab_size, m)\n",
        "    \"\"\"\n",
        "    dL_dZ = softmax_out - Y\n",
        "\n",
        "    assert(dL_dZ.shape == softmax_out.shape)\n",
        "    return dL_dZ\n",
        "\n",
        "def dense_backward(dL_dZ, caches):\n",
        "    \"\"\"\n",
        "    dL_dZ: shape: (vocab_size, m)\n",
        "    caches: dict. results from each steps of forward propagation\n",
        "    \"\"\"\n",
        "    W = caches['W']\n",
        "    word_vec = caches['word_vec']\n",
        "    m = word_vec.shape[1]\n",
        "\n",
        "    dL_dW = (1 / m) * np.dot(dL_dZ, word_vec.T)\n",
        "    dL_dword_vec = np.dot(W.T, dL_dZ)\n",
        "\n",
        "    assert(W.shape == dL_dW.shape)\n",
        "    assert(word_vec.shape == dL_dword_vec.shape)\n",
        "\n",
        "    return dL_dW, dL_dword_vec\n",
        "\n",
        "def backward_propagation(Y, softmax_out, caches):\n",
        "    dL_dZ = softmax_backward(Y, softmax_out)\n",
        "    dL_dW, dL_dword_vec = dense_backward(dL_dZ, caches)\n",
        "\n",
        "    gradients = dict()\n",
        "    gradients['dL_dZ'] = dL_dZ\n",
        "    gradients['dL_dW'] = dL_dW\n",
        "    gradients['dL_dword_vec'] = dL_dword_vec\n",
        "\n",
        "    return gradients\n",
        "\n",
        "def update_parameters(parameters, caches, gradients, learning_rate):\n",
        "    vocab_size, emb_size = parameters['WRD_EMB'].shape\n",
        "    inds = caches['inds']\n",
        "    dL_dword_vec = gradients['dL_dword_vec']\n",
        "    m = inds.shape[-1]\n",
        "\n",
        "    parameters['WRD_EMB'][inds.flatten(), :] -= dL_dword_vec.T * learning_rate\n",
        "\n",
        "    parameters['W'] -= learning_rate * gradients['dL_dW']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkCBQRBLz2iY"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def skipgram_model_training(X, Y, vocab_size, emb_size, learning_rate, epochs, batch_size=256, parameters=None, print_cost=False, plot_cost=True):\n",
        "    costs = []\n",
        "    m = X.shape[1]\n",
        "\n",
        "    if parameters is None:\n",
        "        parameters = initialize_parameters(vocab_size, emb_size)\n",
        "\n",
        "    begin_time = datetime.now()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_cost = 0\n",
        "        batch_inds = list(range(0, m, batch_size))\n",
        "        #print(batch_inds)\n",
        "        np.random.shuffle(batch_inds)\n",
        "        for i in batch_inds:\n",
        "            X_batch = X[:, i:i+batch_size]\n",
        "            Y_batch = Y[:, i:i+batch_size]\n",
        "\n",
        "            softmax_out, caches = forward_propagation(X_batch, parameters)\n",
        "            gradients = backward_propagation(Y_batch, softmax_out, caches)\n",
        "            update_parameters(parameters, caches, gradients, learning_rate)\n",
        "            cost = cross_entropy(softmax_out, Y_batch)\n",
        "            epoch_cost += np.squeeze(cost)\n",
        "\n",
        "        costs.append(epoch_cost)\n",
        "        if print_cost and epoch % (epochs // 500) == 0:\n",
        "            print(\"Cost after epoch {}: {}\".format(epoch, epoch_cost))\n",
        "        if epoch % (epochs // 100) == 0:\n",
        "            learning_rate *= 0.98\n",
        "    end_time = datetime.now()\n",
        "    print('training time: {}'.format(end_time - begin_time))\n",
        "\n",
        "    if plot_cost:\n",
        "        plt.plot(np.arange(epochs), costs)\n",
        "        plt.xlabel('# of epochs')\n",
        "        plt.ylabel('cost')\n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jUVequfQz9cj",
        "outputId": "a07217ad-3e65-433b-d715-f24f41968a4c"
      },
      "source": [
        "paras = skipgram_model_training(X, Y_one_hot, vocab_size, 50, 0.05, 5000, batch_size=128, parameters=None, print_cost=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after epoch 0: 2.5521721116885634\n",
            "Cost after epoch 10: 2.5518728335290817\n",
            "Cost after epoch 20: 2.5515631818966322\n",
            "Cost after epoch 30: 2.551227211923395\n",
            "Cost after epoch 40: 2.550848986573052\n",
            "Cost after epoch 50: 2.5504115473772697\n",
            "Cost after epoch 60: 2.5499065163627157\n",
            "Cost after epoch 70: 2.5493086914266736\n",
            "Cost after epoch 80: 2.5485957622184108\n",
            "Cost after epoch 90: 2.547743637274067\n",
            "Cost after epoch 100: 2.5467249693764744\n",
            "Cost after epoch 110: 2.5455323475388885\n",
            "Cost after epoch 120: 2.5441185061800304\n",
            "Cost after epoch 130: 2.542443114947581\n",
            "Cost after epoch 140: 2.5404628779457865\n",
            "Cost after epoch 150: 2.538128831171577\n",
            "Cost after epoch 160: 2.535439136913629\n",
            "Cost after epoch 170: 2.5323041782368705\n",
            "Cost after epoch 180: 2.528655838081857\n",
            "Cost after epoch 190: 2.5244261507568666\n",
            "Cost after epoch 200: 2.519543560994052\n",
            "Cost after epoch 210: 2.5140426093298798\n",
            "Cost after epoch 220: 2.5077879441081663\n",
            "Cost after epoch 230: 2.5007084733394143\n",
            "Cost after epoch 240: 2.4927555159548804\n",
            "Cost after epoch 250: 2.483899634363601\n",
            "Cost after epoch 260: 2.4743223290596763\n",
            "Cost after epoch 270: 2.4639274326580716\n",
            "Cost after epoch 280: 2.452770653103741\n",
            "Cost after epoch 290: 2.440973173534319\n",
            "Cost after epoch 300: 2.428704054585616\n",
            "Cost after epoch 310: 2.4164011855098266\n",
            "Cost after epoch 320: 2.404100142937139\n",
            "Cost after epoch 330: 2.39201035490301\n",
            "Cost after epoch 340: 2.38035062560438\n",
            "Cost after epoch 350: 2.3693006140408435\n",
            "Cost after epoch 360: 2.3591612348954887\n",
            "Cost after epoch 370: 2.3497976428703025\n",
            "Cost after epoch 380: 2.3411781530169695\n",
            "Cost after epoch 390: 2.3332393740182003\n",
            "Cost after epoch 400: 2.3258779993115044\n",
            "Cost after epoch 410: 2.3190867073711714\n",
            "Cost after epoch 420: 2.312607432763786\n",
            "Cost after epoch 430: 2.306291831356866\n",
            "Cost after epoch 440: 2.300012282475035\n",
            "Cost after epoch 450: 2.293653680850536\n",
            "Cost after epoch 460: 2.287237776741024\n",
            "Cost after epoch 470: 2.2805911835734225\n",
            "Cost after epoch 480: 2.2736484891015505\n",
            "Cost after epoch 490: 2.2663786505409362\n",
            "Cost after epoch 500: 2.2587719296856235\n",
            "Cost after epoch 510: 2.250984460393579\n",
            "Cost after epoch 520: 2.242925899571698\n",
            "Cost after epoch 530: 2.2346218881835864\n",
            "Cost after epoch 540: 2.226124972214684\n",
            "Cost after epoch 550: 2.21749565254717\n",
            "Cost after epoch 560: 2.208955914861882\n",
            "Cost after epoch 570: 2.2004308911596477\n",
            "Cost after epoch 580: 2.1919633278288018\n",
            "Cost after epoch 590: 2.183609276129543\n",
            "Cost after epoch 600: 2.175419149225633\n",
            "Cost after epoch 610: 2.167578836587165\n",
            "Cost after epoch 620: 2.1599890833616935\n",
            "Cost after epoch 630: 2.152661810959782\n",
            "Cost after epoch 640: 2.1456187652509784\n",
            "Cost after epoch 650: 2.138875555751021\n",
            "Cost after epoch 660: 2.1325555035770796\n",
            "Cost after epoch 670: 2.1265504752364266\n",
            "Cost after epoch 680: 2.1208472945724193\n",
            "Cost after epoch 690: 2.115442310262674\n",
            "Cost after epoch 700: 2.1103288217120015\n",
            "Cost after epoch 710: 2.1055826361606975\n",
            "Cost after epoch 720: 2.1011074232446982\n",
            "Cost after epoch 730: 2.0968819152764357\n",
            "Cost after epoch 740: 2.092894192718579\n",
            "Cost after epoch 750: 2.0891320821356048\n",
            "Cost after epoch 760: 2.085645825211888\n",
            "Cost after epoch 770: 2.082360758671483\n",
            "Cost after epoch 780: 2.0792588087526527\n",
            "Cost after epoch 790: 2.076329759515446\n",
            "Cost after epoch 800: 2.073563973394378\n",
            "Cost after epoch 810: 2.0709983725113283\n",
            "Cost after epoch 820: 2.0685783454903572\n",
            "Cost after epoch 830: 2.0662911068171725\n",
            "Cost after epoch 840: 2.0641297980088527\n",
            "Cost after epoch 850: 2.062088051694272\n",
            "Cost after epoch 860: 2.0601939130483142\n",
            "Cost after epoch 870: 2.058407725876045\n",
            "Cost after epoch 880: 2.0567206665991096\n",
            "Cost after epoch 890: 2.0551282221733653\n",
            "Cost after epoch 900: 2.0536261677250325\n",
            "Cost after epoch 910: 2.0522354807438186\n",
            "Cost after epoch 920: 2.050927221722784\n",
            "Cost after epoch 930: 2.049695140558784\n",
            "Cost after epoch 940: 2.048536111132241\n",
            "Cost after epoch 950: 2.047447178630375\n",
            "Cost after epoch 960: 2.046443542201857\n",
            "Cost after epoch 970: 2.0455041746433675\n",
            "Cost after epoch 980: 2.044624574253729\n",
            "Cost after epoch 990: 2.0438024880722296\n",
            "Cost after epoch 1000: 2.0430357730235937\n",
            "Cost after epoch 1010: 2.0423349407870792\n",
            "Cost after epoch 1020: 2.041684986372283\n",
            "Cost after epoch 1030: 2.0410826464828946\n",
            "Cost after epoch 1040: 2.040526225196359\n",
            "Cost after epoch 1050: 2.0400140867120284\n",
            "Cost after epoch 1060: 2.0395528908951612\n",
            "Cost after epoch 1070: 2.0391322488689685\n",
            "Cost after epoch 1080: 2.038749736895246\n",
            "Cost after epoch 1090: 2.0384039563288625\n",
            "Cost after epoch 1100: 2.038093527853034\n",
            "Cost after epoch 1110: 2.037821922738001\n",
            "Cost after epoch 1120: 2.037582281439997\n",
            "Cost after epoch 1130: 2.0373727209947243\n",
            "Cost after epoch 1140: 2.0371919639644265\n",
            "Cost after epoch 1150: 2.0370387324577823\n",
            "Cost after epoch 1160: 2.0369139526937134\n",
            "Cost after epoch 1170: 2.036813465026184\n",
            "Cost after epoch 1180: 2.0367357587180885\n",
            "Cost after epoch 1190: 2.0366796185733635\n",
            "Cost after epoch 1200: 2.036643829727081\n",
            "Cost after epoch 1210: 2.0366274527037254\n",
            "Cost after epoch 1220: 2.0366283808500545\n",
            "Cost after epoch 1230: 2.0366454085713843\n",
            "Cost after epoch 1240: 2.0366774063077315\n",
            "Cost after epoch 1250: 2.036723254973063\n",
            "Cost after epoch 1260: 2.0367808146709465\n",
            "Cost after epoch 1270: 2.0368494915114157\n",
            "Cost after epoch 1280: 2.0369283591039236\n",
            "Cost after epoch 1290: 2.037016419661038\n",
            "Cost after epoch 1300: 2.0371126957744115\n",
            "Cost after epoch 1310: 2.037214429388171\n",
            "Cost after epoch 1320: 2.037322067257219\n",
            "Cost after epoch 1330: 2.0374349376382863\n",
            "Cost after epoch 1340: 2.037552208380071\n",
            "Cost after epoch 1350: 2.037673074230046\n",
            "Cost after epoch 1360: 2.0377946237576157\n",
            "Cost after epoch 1370: 2.0379179384960144\n",
            "Cost after epoch 1380: 2.038042569828389\n",
            "Cost after epoch 1390: 2.0381678675969805\n",
            "Cost after epoch 1400: 2.038293212460958\n",
            "Cost after epoch 1410: 2.0384158846799054\n",
            "Cost after epoch 1420: 2.0385372720913346\n",
            "Cost after epoch 1430: 2.038657116971419\n",
            "Cost after epoch 1440: 2.0387749565479143\n",
            "Cost after epoch 1450: 2.0388903613140883\n",
            "Cost after epoch 1460: 2.039001037331607\n",
            "Cost after epoch 1470: 2.0391084338467746\n",
            "Cost after epoch 1480: 2.0392124559232285\n",
            "Cost after epoch 1490: 2.039312826488902\n",
            "Cost after epoch 1500: 2.0394093026266216\n",
            "Cost after epoch 1510: 2.0395001463466147\n",
            "Cost after epoch 1520: 2.039586703433144\n",
            "Cost after epoch 1530: 2.039669016099289\n",
            "Cost after epoch 1540: 2.039746982029873\n",
            "Cost after epoch 1550: 2.039820531365921\n",
            "Cost after epoch 1560: 2.0398885134979254\n",
            "Cost after epoch 1570: 2.0399520752595053\n",
            "Cost after epoch 1580: 2.040011367379687\n",
            "Cost after epoch 1590: 2.0400664374295965\n",
            "Cost after epoch 1600: 2.040117360206006\n",
            "Cost after epoch 1610: 2.0401635151493407\n",
            "Cost after epoch 1620: 2.0402058102745313\n",
            "Cost after epoch 1630: 2.0402444688507653\n",
            "Cost after epoch 1640: 2.040279647470553\n",
            "Cost after epoch 1650: 2.0403115212358522\n",
            "Cost after epoch 1660: 2.0403398739304524\n",
            "Cost after epoch 1670: 2.040365376365795\n",
            "Cost after epoch 1680: 2.0403882813727194\n",
            "Cost after epoch 1690: 2.0404088014626858\n",
            "Cost after epoch 1700: 2.0404271568361243\n",
            "Cost after epoch 1710: 2.0404433731506506\n",
            "Cost after epoch 1720: 2.0404579139311796\n",
            "Cost after epoch 1730: 2.040471017335634\n",
            "Cost after epoch 1740: 2.0404828959906802\n",
            "Cost after epoch 1750: 2.0404937596455808\n",
            "Cost after epoch 1760: 2.0405037141926887\n",
            "Cost after epoch 1770: 2.040513062169997\n",
            "Cost after epoch 1780: 2.040521990434852\n",
            "Cost after epoch 1790: 2.040530665285545\n",
            "Cost after epoch 1800: 2.040539242264879\n",
            "Cost after epoch 1810: 2.0405477808393413\n",
            "Cost after epoch 1820: 2.0405564743882105\n",
            "Cost after epoch 1830: 2.0405654373385578\n",
            "Cost after epoch 1840: 2.040574762363697\n",
            "Cost after epoch 1850: 2.040584527764173\n",
            "Cost after epoch 1860: 2.040594676371592\n",
            "Cost after epoch 1870: 2.0406053401920774\n",
            "Cost after epoch 1880: 2.040616559088582\n",
            "Cost after epoch 1890: 2.0406283479431533\n",
            "Cost after epoch 1900: 2.0406407081966793\n",
            "Cost after epoch 1910: 2.0406534565902494\n",
            "Cost after epoch 1920: 2.0406667005031953\n",
            "Cost after epoch 1930: 2.0406804204265443\n",
            "Cost after epoch 1940: 2.0406945701442063\n",
            "Cost after epoch 1950: 2.0407090946502584\n",
            "Cost after epoch 1960: 2.040723724523587\n",
            "Cost after epoch 1970: 2.040738565336781\n",
            "Cost after epoch 1980: 2.040753565294317\n",
            "Cost after epoch 1990: 2.040768647814933\n",
            "Cost after epoch 2000: 2.0407837343029844\n",
            "Cost after epoch 2010: 2.040798536481517\n",
            "Cost after epoch 2020: 2.040813168266077\n",
            "Cost after epoch 2030: 2.0408275769454716\n",
            "Cost after epoch 2040: 2.040841690815414\n",
            "Cost after epoch 2050: 2.0408554429937693\n",
            "Cost after epoch 2060: 2.040868594446237\n",
            "Cost after epoch 2070: 2.040881268593176\n",
            "Cost after epoch 2080: 2.0408934389363815\n",
            "Cost after epoch 2090: 2.0409050679871754\n",
            "Cost after epoch 2100: 2.0409161279291608\n",
            "Cost after epoch 2110: 2.0409264736386317\n",
            "Cost after epoch 2120: 2.0409362346472237\n",
            "Cost after epoch 2130: 2.040945426293514\n",
            "Cost after epoch 2140: 2.04095406045266\n",
            "Cost after epoch 2150: 2.040962160267223\n",
            "Cost after epoch 2160: 2.040969681296407\n",
            "Cost after epoch 2170: 2.040976755933963\n",
            "Cost after epoch 2180: 2.0409834424867013\n",
            "Cost after epoch 2190: 2.0409898003690183\n",
            "Cost after epoch 2200: 2.040995898650032\n",
            "Cost after epoch 2210: 2.041001762176665\n",
            "Cost after epoch 2220: 2.0410075276842385\n",
            "Cost after epoch 2230: 2.041013285705969\n",
            "Cost after epoch 2240: 2.041019128022315\n",
            "Cost after epoch 2250: 2.041025152407247\n",
            "Cost after epoch 2260: 2.0410313955161454\n",
            "Cost after epoch 2270: 2.0410380076789867\n",
            "Cost after epoch 2280: 2.0410450953292294\n",
            "Cost after epoch 2290: 2.0410527614722302\n",
            "Cost after epoch 2300: 2.0410611109079597\n",
            "Cost after epoch 2310: 2.041070126101076\n",
            "Cost after epoch 2320: 2.041079987942581\n",
            "Cost after epoch 2330: 2.0410908032077537\n",
            "Cost after epoch 2340: 2.041102666162611\n",
            "Cost after epoch 2350: 2.0411156692948724\n",
            "Cost after epoch 2360: 2.0411296821907934\n",
            "Cost after epoch 2370: 2.041144937693302\n",
            "Cost after epoch 2380: 2.041161531989957\n",
            "Cost after epoch 2390: 2.0411795361732064\n",
            "Cost after epoch 2400: 2.0411990171609165\n",
            "Cost after epoch 2410: 2.041219690392626\n",
            "Cost after epoch 2420: 2.0412418614519625\n",
            "Cost after epoch 2430: 2.041265610583584\n",
            "Cost after epoch 2440: 2.0412909780492057\n",
            "Cost after epoch 2450: 2.0413179987571386\n",
            "Cost after epoch 2460: 2.041346214101828\n",
            "Cost after epoch 2470: 2.04137601779599\n",
            "Cost after epoch 2480: 2.0414074733632535\n",
            "Cost after epoch 2490: 2.0414405885216933\n",
            "Cost after epoch 2500: 2.0414753654407054\n",
            "Cost after epoch 2510: 2.0415111722858925\n",
            "Cost after epoch 2520: 2.041548497670455\n",
            "Cost after epoch 2530: 2.041587390477301\n",
            "Cost after epoch 2540: 2.0416278284212495\n",
            "Cost after epoch 2550: 2.0416697841452787\n",
            "Cost after epoch 2560: 2.0417124708119125\n",
            "Cost after epoch 2570: 2.041756468868293\n",
            "Cost after epoch 2580: 2.041801815884447\n",
            "Cost after epoch 2590: 2.041848464645734\n",
            "Cost after epoch 2600: 2.04189636373404\n",
            "Cost after epoch 2610: 2.0419446025377974\n",
            "Cost after epoch 2620: 2.0419938409341456\n",
            "Cost after epoch 2630: 2.0420441085999177\n",
            "Cost after epoch 2640: 2.042095339621328\n",
            "Cost after epoch 2650: 2.04214746492827\n",
            "Cost after epoch 2660: 2.042199489832062\n",
            "Cost after epoch 2670: 2.0422521335537946\n",
            "Cost after epoch 2680: 2.0423054207172107\n",
            "Cost after epoch 2690: 2.042359273133955\n",
            "Cost after epoch 2700: 2.0424136105392026\n",
            "Cost after epoch 2710: 2.0424673981852886\n",
            "Cost after epoch 2720: 2.042521389106988\n",
            "Cost after epoch 2730: 2.0425756048406716\n",
            "Cost after epoch 2740: 2.042629960932011\n",
            "Cost after epoch 2750: 2.0426843718690346\n",
            "Cost after epoch 2760: 2.0427378076603433\n",
            "Cost after epoch 2770: 2.0427910265548324\n",
            "Cost after epoch 2780: 2.0428440480438272\n",
            "Cost after epoch 2790: 2.0428967866477206\n",
            "Cost after epoch 2800: 2.0429491567307654\n",
            "Cost after epoch 2810: 2.043000175848974\n",
            "Cost after epoch 2820: 2.043050578014161\n",
            "Cost after epoch 2830: 2.0431003808823407\n",
            "Cost after epoch 2840: 2.0431495022469366\n",
            "Cost after epoch 2850: 2.043197860499057\n",
            "Cost after epoch 2860: 2.043244559390938\n",
            "Cost after epoch 2870: 2.04329028028756\n",
            "Cost after epoch 2880: 2.0433350385455187\n",
            "Cost after epoch 2890: 2.0433787585320076\n",
            "Cost after epoch 2900: 2.043421365805865\n",
            "Cost after epoch 2910: 2.0434620833645476\n",
            "Cost after epoch 2920: 2.043501514050282\n",
            "Cost after epoch 2930: 2.0435396699650443\n",
            "Cost after epoch 2940: 2.043576484378076\n",
            "Cost after epoch 2950: 2.0436118921851674\n",
            "Cost after epoch 2960: 2.0436452622146444\n",
            "Cost after epoch 2970: 2.0436770965195\n",
            "Cost after epoch 2980: 2.0437074026823208\n",
            "Cost after epoch 2990: 2.04373612430924\n",
            "Cost after epoch 3000: 2.0437632069188987\n",
            "Cost after epoch 3010: 2.0437881849412363\n",
            "Cost after epoch 3020: 2.043811441663134\n",
            "Cost after epoch 3030: 2.0438329787397977\n",
            "Cost after epoch 3040: 2.043852750769507\n",
            "Cost after epoch 3050: 2.043870714416633\n",
            "Cost after epoch 3060: 2.0438865827381565\n",
            "Cost after epoch 3070: 2.0439006068957513\n",
            "Cost after epoch 3080: 2.043912781209588\n",
            "Cost after epoch 3090: 2.043923071279436\n",
            "Cost after epoch 3100: 2.0439314448129293\n",
            "Cost after epoch 3110: 2.0439378001708337\n",
            "Cost after epoch 3120: 2.04394224767985\n",
            "Cost after epoch 3130: 2.0439447730346054\n",
            "Cost after epoch 3140: 2.043945352340847\n",
            "Cost after epoch 3150: 2.0439439637645647\n",
            "Cost after epoch 3160: 2.0439406919298757\n",
            "Cost after epoch 3170: 2.043935502063317\n",
            "Cost after epoch 3180: 2.043928370148966\n",
            "Cost after epoch 3190: 2.0439192819363354\n",
            "Cost after epoch 3200: 2.043908225120571\n",
            "Cost after epoch 3210: 2.043895466612504\n",
            "Cost after epoch 3220: 2.04388082633715\n",
            "Cost after epoch 3230: 2.0438642697485627\n",
            "Cost after epoch 3240: 2.043845791138308\n",
            "Cost after epoch 3250: 2.0438253865829155\n",
            "Cost after epoch 3260: 2.0438034972226635\n",
            "Cost after epoch 3270: 2.043779801043622\n",
            "Cost after epoch 3280: 2.0437542524492476\n",
            "Cost after epoch 3290: 2.0437268530425485\n",
            "Cost after epoch 3300: 2.0436976060232186\n",
            "Cost after epoch 3310: 2.043667115491504\n",
            "Cost after epoch 3320: 2.0436349238527636\n",
            "Cost after epoch 3330: 2.0436009742478203\n",
            "Cost after epoch 3340: 2.043565274322504\n",
            "Cost after epoch 3350: 2.0435278331187714\n",
            "Cost after epoch 3360: 2.0434894040487794\n",
            "Cost after epoch 3370: 2.043449402697532\n",
            "Cost after epoch 3380: 2.043407761029596\n",
            "Cost after epoch 3390: 2.043364491497168\n",
            "Cost after epoch 3400: 2.0433196077477933\n",
            "Cost after epoch 3410: 2.043273997243989\n",
            "Cost after epoch 3420: 2.0432269593286922\n",
            "Cost after epoch 3430: 2.043178415149601\n",
            "Cost after epoch 3440: 2.0431283808113543\n",
            "Cost after epoch 3450: 2.043076873421808\n",
            "Cost after epoch 3460: 2.0430248982941492\n",
            "Cost after epoch 3470: 2.0429716503766233\n",
            "Cost after epoch 3480: 2.042917040596416\n",
            "Cost after epoch 3490: 2.0428610876718585\n",
            "Cost after epoch 3500: 2.042803811147006\n",
            "Cost after epoch 3510: 2.0427463176229357\n",
            "Cost after epoch 3520: 2.0426877102740373\n",
            "Cost after epoch 3530: 2.042627890597982\n",
            "Cost after epoch 3540: 2.042566879020985\n",
            "Cost after epoch 3550: 2.0425046966357265\n",
            "Cost after epoch 3560: 2.0424425348777473\n",
            "Cost after epoch 3570: 2.042379418110223\n",
            "Cost after epoch 3580: 2.0423152393421224\n",
            "Cost after epoch 3590: 2.042250019940704\n",
            "Cost after epoch 3600: 2.0421837818003135\n",
            "Cost after epoch 3610: 2.0421177852206895\n",
            "Cost after epoch 3620: 2.0420509886951805\n",
            "Cost after epoch 3630: 2.041983277790465\n",
            "Cost after epoch 3640: 2.0419146741842673\n",
            "Cost after epoch 3650: 2.041845199962102\n",
            "Cost after epoch 3660: 2.0417761690838634\n",
            "Cost after epoch 3670: 2.041706486798842\n",
            "Cost after epoch 3680: 2.041636032342091\n",
            "Cost after epoch 3690: 2.0415648271987754\n",
            "Cost after epoch 3700: 2.041492893161816\n",
            "Cost after epoch 3710: 2.0414215836161955\n",
            "Cost after epoch 3720: 2.041349762648139\n",
            "Cost after epoch 3730: 2.0412773042990677\n",
            "Cost after epoch 3740: 2.041204229473706\n",
            "Cost after epoch 3750: 2.0411305593022595\n",
            "Cost after epoch 3760: 2.0410576734625616\n",
            "Cost after epoch 3770: 2.040984406244338\n",
            "Cost after epoch 3780: 2.040910627629089\n",
            "Cost after epoch 3790: 2.040836357654012\n",
            "Cost after epoch 3800: 2.040761616515425\n",
            "Cost after epoch 3810: 2.040687798231112\n",
            "Cost after epoch 3820: 2.0406137178292236\n",
            "Cost after epoch 3830: 2.040539242334781\n",
            "Cost after epoch 3840: 2.0404643907162865\n",
            "Cost after epoch 3850: 2.040389182048884\n",
            "Cost after epoch 3860: 2.0403150139469157\n",
            "Cost after epoch 3870: 2.0402406918078024\n",
            "Cost after epoch 3880: 2.0401660807528375\n",
            "Cost after epoch 3890: 2.040091198552078\n",
            "Cost after epoch 3900: 2.0400160630416035\n",
            "Cost after epoch 3910: 2.039942065892206\n",
            "Cost after epoch 3920: 2.0398680115620706\n",
            "Cost after epoch 3930: 2.0397937642555903\n",
            "Cost after epoch 3940: 2.0397193404725678\n",
            "Cost after epoch 3950: 2.039644756748129\n",
            "Cost after epoch 3960: 2.03957139043892\n",
            "Cost after epoch 3970: 2.039498052810639\n",
            "Cost after epoch 3980: 2.039424608061126\n",
            "Cost after epoch 3990: 2.039351071393926\n",
            "Cost after epoch 4000: 2.0392774580253716\n",
            "Cost after epoch 4010: 2.0392051237430664\n",
            "Cost after epoch 4020: 2.039132893440143\n",
            "Cost after epoch 4030: 2.0390606321351816\n",
            "Cost after epoch 4040: 2.038988353744702\n",
            "Cost after epoch 4050: 2.0389160721820407\n",
            "Cost after epoch 4060: 2.03884511545903\n",
            "Cost after epoch 4070: 2.0387743280246857\n",
            "Cost after epoch 4080: 2.038703576459397\n",
            "Cost after epoch 4090: 2.0386328734280568\n",
            "Cost after epoch 4100: 2.038562231581608\n",
            "Cost after epoch 4110: 2.038492945921435\n",
            "Cost after epoch 4120: 2.0384238855372314\n",
            "Cost after epoch 4130: 2.0383549192255543\n",
            "Cost after epoch 4140: 2.0382860584537017\n",
            "Cost after epoch 4150: 2.0382173146682674\n",
            "Cost after epoch 4160: 2.038149945516932\n",
            "Cost after epoch 4170: 2.038082849027329\n",
            "Cost after epoch 4180: 2.0380158967814896\n",
            "Cost after epoch 4190: 2.037949099115571\n",
            "Cost after epoch 4200: 2.037882466341314\n",
            "Cost after epoch 4210: 2.0378172152189613\n",
            "Cost after epoch 4220: 2.0377522762847744\n",
            "Cost after epoch 4230: 2.037687524393756\n",
            "Cost after epoch 4240: 2.037622968824855\n",
            "Cost after epoch 4250: 2.0375586188311066\n",
            "Cost after epoch 4260: 2.0374956474802883\n",
            "Cost after epoch 4270: 2.0374330207245506\n",
            "Cost after epoch 4280: 2.0373706171019528\n",
            "Cost after epoch 4290: 2.03730844491173\n",
            "Cost after epoch 4300: 2.0372465124272705\n",
            "Cost after epoch 4310: 2.0371859468696774\n",
            "Cost after epoch 4320: 2.037125751913973\n",
            "Cost after epoch 4330: 2.037065810119112\n",
            "Cost after epoch 4340: 2.037006128882693\n",
            "Cost after epoch 4350: 2.0369467155775776\n",
            "Cost after epoch 4360: 2.036888650000988\n",
            "Cost after epoch 4370: 2.0368309753191984\n",
            "Cost after epoch 4380: 2.0367735783832424\n",
            "Cost after epoch 4390: 2.0367164657655352\n",
            "Cost after epoch 4400: 2.0366596440154883\n",
            "Cost after epoch 4410: 2.036604144437375\n",
            "Cost after epoch 4420: 2.036549050977452\n",
            "Cost after epoch 4430: 2.036494254989204\n",
            "Cost after epoch 4440: 2.0364397622931025\n",
            "Cost after epoch 4450: 2.03638557868866\n",
            "Cost after epoch 4460: 2.0363326863627704\n",
            "Cost after epoch 4470: 2.0362802109062916\n",
            "Cost after epoch 4480: 2.0362280483305484\n",
            "Cost after epoch 4490: 2.036176203773039\n",
            "Cost after epoch 4500: 2.0361246823524306\n",
            "Cost after epoch 4510: 2.0360744169005103\n",
            "Cost after epoch 4520: 2.036024575144833\n",
            "Cost after epoch 4530: 2.0359750578606937\n",
            "Cost after epoch 4540: 2.03592586956668\n",
            "Cost after epoch 4550: 2.03587701476459\n",
            "Cost after epoch 4560: 2.0358293770276887\n",
            "Cost after epoch 4570: 2.0357821663872384\n",
            "Cost after epoch 4580: 2.0357352884448527\n",
            "Cost after epoch 4590: 2.035688747159048\n",
            "Cost after epoch 4600: 2.0356425464734067\n",
            "Cost after epoch 4610: 2.035597521086556\n",
            "Cost after epoch 4620: 2.03555292321856\n",
            "Cost after epoch 4630: 2.0355086633211146\n",
            "Cost after epoch 4640: 2.0354647448462284\n",
            "Cost after epoch 4650: 2.035421171232577\n",
            "Cost after epoch 4660: 2.035378728933426\n",
            "Cost after epoch 4670: 2.0353367119998276\n",
            "Cost after epoch 4680: 2.035295035723581\n",
            "Cost after epoch 4690: 2.035253703098604\n",
            "Cost after epoch 4700: 2.035212717106803\n",
            "Cost after epoch 4710: 2.0351728167935876\n",
            "Cost after epoch 4720: 2.035133337475273\n",
            "Cost after epoch 4730: 2.0350941992445106\n",
            "Cost after epoch 4740: 2.03505540468068\n",
            "Cost after epoch 4750: 2.0350169563521754\n",
            "Cost after epoch 4760: 2.0349795469094754\n",
            "Cost after epoch 4770: 2.034942552191749\n",
            "Cost after epoch 4780: 2.0349058970280867\n",
            "Cost after epoch 4790: 2.0348695836223607\n",
            "Cost after epoch 4800: 2.034833614168227\n",
            "Cost after epoch 4810: 2.0347986360807013\n",
            "Cost after epoch 4820: 2.034764064830454\n",
            "Cost after epoch 4830: 2.034729829897154\n",
            "Cost after epoch 4840: 2.034695933144113\n",
            "Cost after epoch 4850: 2.0346623764249534\n",
            "Cost after epoch 4860: 2.0346297631998995\n",
            "Cost after epoch 4870: 2.034597547555371\n",
            "Cost after epoch 4880: 2.0345656635176756\n",
            "Cost after epoch 4890: 2.0345341126408623\n",
            "Cost after epoch 4900: 2.0345028964696223\n",
            "Cost after epoch 4910: 2.034472575889014\n",
            "Cost after epoch 4920: 2.034442642482735\n",
            "Cost after epoch 4930: 2.0344130347047353\n",
            "Cost after epoch 4940: 2.0343837538278966\n",
            "Cost after epoch 4950: 2.034354801115919\n",
            "Cost after epoch 4960: 2.034326696337773\n",
            "Cost after epoch 4970: 2.0342989673723584\n",
            "Cost after epoch 4980: 2.0342715569698977\n",
            "Cost after epoch 4990: 2.0342444661474333\n",
            "training time: 0:00:01.009710\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxfKEn_l817b",
        "outputId": "690bc52e-a267-41a3-9de3-0e43ae2bb892"
      },
      "source": [
        "X_test = np.arange(vocab_size)\n",
        "print(X_test.shape)\n",
        "X_test = np.expand_dims(X_test, axis=0)\n",
        "print(X_test.shape)\n",
        "softmax_test, _ = forward_propagation(X_test, paras)\n",
        "print(softmax_test)\n",
        "top_sorted_inds = np.argsort(softmax_test, axis=0)[-4:,:]\n",
        "print(top_sorted_inds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13,)\n",
            "(1, 13)\n",
            "[[2.90837764e-02 2.08496752e-01 8.85757791e-02 1.25822002e-01\n",
            "  1.56701545e-01 1.26252316e-01 3.98542961e-03 1.25631284e-01\n",
            "  6.67041331e-02 1.92339643e-02 1.28840632e-02 6.66255112e-02\n",
            "  2.03462057e-02]\n",
            " [1.90280149e-01 2.39692730e-05 7.76211987e-02 1.21679859e-03\n",
            "  1.21638178e-01 1.20506251e-03 5.08379070e-02 1.19023308e-03\n",
            "  1.57975775e-02 3.71979431e-03 9.77800128e-02 1.57631373e-02\n",
            "  8.15532564e-04]\n",
            " [8.53966922e-02 3.64127438e-01 7.81967272e-02 5.48917307e-02\n",
            "  8.74166359e-02 5.50793744e-02 3.90923670e-01 5.48548657e-02\n",
            "  4.54937907e-02 2.07235643e-01 1.14580926e-01 4.56042414e-02\n",
            "  2.20366368e-01]\n",
            " [1.41355354e-01 4.24382585e-02 1.25792763e-01 1.18953415e-01\n",
            "  4.95815662e-02 1.19306731e-01 1.40080004e-02 1.18589224e-01\n",
            "  1.93002911e-01 2.28767077e-02 4.29200774e-02 1.93106395e-01\n",
            "  2.63524394e-03]\n",
            " [9.78261174e-02 9.37641720e-02 1.00813225e-01 1.09159601e-02\n",
            "  9.58077116e-03 1.08660715e-02 7.78907295e-02 1.07990599e-02\n",
            "  9.96754762e-02 5.08362151e-02 2.31116516e-01 9.92204700e-02\n",
            "  4.75299846e-02]\n",
            " [1.55723298e-01 5.04032310e-02 8.37666446e-02 1.22721592e-01\n",
            "  4.71477355e-02 1.22453454e-01 1.43734621e-02 1.21514887e-01\n",
            "  1.73032975e-01 3.65852916e-02 5.81039957e-02 1.73013815e-01\n",
            "  2.22092233e-03]\n",
            " [4.51551710e-02 6.21748344e-02 1.18307827e-01 8.95945131e-03\n",
            "  5.25688024e-02 8.99472292e-03 1.69266813e-01 9.00508826e-03\n",
            "  2.94095624e-02 4.49226667e-02 1.81727117e-01 2.94492591e-02\n",
            "  4.51895691e-01]\n",
            " [5.62803151e-02 6.76097022e-02 6.23897083e-02 1.26019519e-01\n",
            "  2.64312353e-02 1.26660250e-01 6.55210064e-03 1.25385159e-01\n",
            "  1.78479206e-01 3.91421283e-02 3.08641976e-02 1.78290634e-01\n",
            "  4.08217569e-03]\n",
            " [9.96658342e-02 1.22897455e-02 8.66795813e-02 1.85623892e-01\n",
            "  2.48915869e-01 1.84574075e-01 1.12042721e-02 1.86626961e-01\n",
            "  4.06676553e-02 1.22429314e-02 3.58219287e-02 4.09140044e-02\n",
            "  2.82554286e-03]\n",
            " [1.26234344e-02 1.78801860e-03 4.97942928e-02 5.11434659e-03\n",
            "  8.65741143e-04 5.18987439e-03 6.13222266e-02 5.17574126e-03\n",
            "  6.70316994e-02 1.07299149e-02 1.39437751e-01 6.69951379e-02\n",
            "  1.45443680e-01]\n",
            " [1.76283514e-02 6.60154757e-02 4.68085728e-02 2.26106615e-02\n",
            "  1.22314607e-01 2.26383258e-02 1.29804913e-01 2.25530878e-02\n",
            "  1.34539924e-02 2.81817668e-01 9.80255724e-03 1.34480111e-02\n",
            "  9.55646557e-02]\n",
            " [2.63145017e-02 2.96640140e-02 2.81152111e-02 2.03182554e-01\n",
            "  6.10859731e-02 2.02970722e-01 4.00266365e-03 2.04727951e-01\n",
            "  3.24905254e-02 3.48632874e-02 3.74704422e-02 3.25882704e-02\n",
            "  5.52763822e-03]\n",
            " [4.26097208e-02 1.18418081e-03 5.30667425e-02 1.39329857e-02\n",
            "  1.57083417e-02 1.37739385e-02 6.57969998e-02 1.39114433e-02\n",
            "  4.47050896e-02 2.35756424e-01 7.44255101e-03 4.49256621e-02\n",
            "  7.33594714e-04]]\n",
            "[[ 8  7  0  0  1  0  4  7  4  4  2  4 10]\n",
            " [ 3  4  4  7 10  7 10  0  5  2  9  5  9]\n",
            " [ 5  0  6  8  0  8  6  8  7 12  6  7  2]\n",
            " [ 1  2  3 11  8 11  2 11  3 10  4  3  6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKGKD77683uK",
        "outputId": "9e8fba14-3e5c-4715-fd9b-ba8f38ad4b8d"
      },
      "source": [
        "for input_ind in range(vocab_size):\n",
        "    print(input_ind)\n",
        "    input_word = id_to_word[input_ind]\n",
        "    print(input_word)\n",
        "    print(top_sorted_inds[::-1,input_ind])\n",
        "    output_words = [id_to_word[output_ind] for output_ind in top_sorted_inds[::-1, input_ind]]\n",
        "    print(\"{}'s neighbor words: {}\".format(input_word, output_words))\n",
        "#After the deduction of the costs of investing, beating deduction the stock market deduction is a loser's game.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "stock\n",
            "[1 5 3 8]\n",
            "stock's neighbor words: ['investing', 'a', 'is', 'market']\n",
            "1\n",
            "investing\n",
            "[2 0 4 7]\n",
            "investing's neighbor words: ['the', 'stock', 'beating', \"loser's\"]\n",
            "2\n",
            "the\n",
            "[3 6 4 0]\n",
            "the's neighbor words: ['is', 'of', 'beating', 'stock']\n",
            "3\n",
            "is\n",
            "[11  8  7  0]\n",
            "is's neighbor words: ['game', 'market', \"loser's\", 'stock']\n",
            "4\n",
            "beating\n",
            "[ 8  0 10  1]\n",
            "beating's neighbor words: ['market', 'stock', 'costs', 'investing']\n",
            "5\n",
            "a\n",
            "[11  8  7  0]\n",
            "a's neighbor words: ['game', 'market', \"loser's\", 'stock']\n",
            "6\n",
            "of\n",
            "[ 2  6 10  4]\n",
            "of's neighbor words: ['the', 'of', 'costs', 'beating']\n",
            "7\n",
            "loser's\n",
            "[11  8  0  7]\n",
            "loser's's neighbor words: ['game', 'market', 'stock', \"loser's\"]\n",
            "8\n",
            "market\n",
            "[3 7 5 4]\n",
            "market's neighbor words: ['is', \"loser's\", 'a', 'beating']\n",
            "9\n",
            "deduction\n",
            "[10 12  2  4]\n",
            "deduction's neighbor words: ['costs', 'after', 'the', 'beating']\n",
            "10\n",
            "costs\n",
            "[4 6 9 2]\n",
            "costs's neighbor words: ['beating', 'of', 'deduction', 'the']\n",
            "11\n",
            "game\n",
            "[3 7 5 4]\n",
            "game's neighbor words: ['is', \"loser's\", 'a', 'beating']\n",
            "12\n",
            "after\n",
            "[ 6  2  9 10]\n",
            "after's neighbor words: ['of', 'the', 'deduction', 'costs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qcvBSEy9w5F"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}